هوالمحبوب

کاربر: user
کالا: item
*: نوشته‌ی کاربری‌ها رم اضافه کنم. اینو لاتک کنم اگه وقت شد.

از اونجا که این پروژه بیشتر یک پروژه تحقیقاتی است و یک هدف کارفرما یاد گرفتن و ارزیابی الگوریتم‌های مختلف این کار است روی سندها و ارائه‌های این بخش از کار هم باید وقت بگذاریم.
این نوشته پیش‌نویس اولیه‌ی توضیح الگوریتم‌های پیاده‌سازی موتور توصیه‌گر و الگوریتم‌های ارزیابی‌ است. اینجا به شکل خیلی همینجوری الگوریتم‌هایی که پیاده شدند رو توضیح میدیم تا اگر نیاز شد سند جدی‌تری بنویسیم از این پیش‌نویس استفاده کنیم.

الگوریتم‌های پیش‌بینی
منطقا امتیاز کاربرها رو روی کالاهایی که انتخاب نکرده‌اند پیش‌بینی می‌کنند. اصل محتوای این بخش رو از داک surprise scikit برداشتیم.i
تابع پیش‌بینی نرمال(randomNormalPred)
این تابع پیش‌بینی به این شکل‌ه که یک توزیع نرمال می‌ندازه روی امتیازها و برای پیش‌بینی امتیاز از این توزیعی که درست کرده یه عدد رندم می‌گیره. پارامترهای توزیع نرمالی که درست می‌کنه:





(این پارامترها رو هم مثل بقیه توزیع‌ها از MLE(Maximum Likelihood Estimation) iiمیشه به دست آورد.)
چیزی که معلوم‌ه همین‌ه که خیلی مدل دقیقی نیست معمولا؛ برای ۲۰۰تا فیلم اول که اجراش کردیم(۲۰درصد داده تست) این نتیجه رو توی Kfold داد: یادم باشه توی الگوریتم ارزیابی‌ها kfold رو بگم
Evaluating RMSE, MAE of algorithm NormalPredictor on 5 split(s).
                         Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     
RMSE (testset)    1.4416  1.4458  1.4429  1.4435  1.4436  1.4435  0.0014  
MAE (testset)     1.1540  1.1566  1.1561  1.1550  1.1566  1.1557  0.0010 

تابع پیش‌بینی بایاس خطی(baseLinePred)
این تابع هم مثل قبلی خیلی ساده و ابتدایی است؛ بایاس کاربر در امتیازدهی و بایاس کالا در امتیازگیری را حساب می‌کند و با اضافه کردن آن به میانگین کل امتیازها امتیاز کاربر به کالا را پیش‌بینی می‌کند. این پیش‌بینی خیلی به عنوان تنها تابعی که استفاده شود دقت خوبی ندارد، ولی بعضی مواقع برای اعمال بایاس اولیه روی داده‌های منطقه‌ای برای انجام پیش‌بینی با یک تابع پیش‌بینی دیگر استفاده می‌شود که خوب نتیجه می‌دهد.(اون کانتست نت‌فلیکس هم یکی از بخش‌های الگوریتم نفر اول یک همچنین چیزی بود.)



منطقا لود محاسباتی این تابع از تابع قسمت قبل بیشتر است ولی نتیجه‌ی به نسبت بهتری هم می‌دهد که می‌توانید نتیجه‌ی آن را روی ۲۰۰ داده ببینید.
                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     
RMSE (testset)    0.9645  0.9691  0.9671  0.9648  0.9688  0.9669  0.0019  
MAE (testset)     0.7604  0.7637  0.7624  0.7604  0.7632  0.7620  0.0014  
Fit time          3.90    5.03    4.35    4.48    32.26   10.00   11.13 
این که چجوری این bها به دست می‌آیند به دو شکل می‌تونیم اندازه‌گیری‌شون کنیم. روش اول طبق معمول کمینه کردن خطا توی فرمول زیر هست که جمله‌ی اول خطای اندازه‌گیری ما روی داده‌ی آموزش و جمله‌ی دوم regularizationای هست که گذاشته می‌شود برای این که جلوی over fit شدن گرفته بشه. (از اونجایی هم که تابع محدب است می‌تونیم مثل بقیه جاها مثلا از SGDiii برای پیدا کردن min استفاده کنیم.). کتابخونه‌ی surprise scikit-learn که ما استفاده کردیم از این راه‌حل استفاده می‌کند.

یک راه ساده‌تر هم منطقا این هستش که از راه زیر بایاس‌ها رو به دست بیاریم. باز پارامترهای لاندا برای جلوگیری از over fit گذاشته می‌شه که با ارزیابی مدل‌هایی از جنس cross-validation می‌تونیم اون‌ها رو اندازه بگیریم و مقدار نسبتا خوبی بدیم.iv










تابع knn
کلیت تابع knn همون تابع معمول k nearest neighbour هست. این تابع شاید مرسوم‌ترین تابع برای موتور توصیه‌گرهای تعاملی (collaborative) هست. این تابع یک سری ورودی‌ها داره که یک حالت پیش‌فرض دارند و می‌شود کاربری که از تابع استفاده می‌کند این تابع‌ها رو تنظیم کند با ورودی‌های خود. پس این ورودی‌ها را توضیح می‌دهیم.
    • کلا به دو شکل از این تابع استفاده می‌شه، یه شکل اینطوری می‌شه که بیایم کاربرهای مشابه رو پیدا کنیم و بعدش برای پیشنهاد کالای جدید به کاربر موردنظر از کالاهای انتخاب‌شده‌ی کاربرهای مشابه استفاده کنیم؛ یه شکل اینطوری می‌شه که کالاهای مشابه رو پیدا کنیم و برای پیشنهاد کالای جدید به کاربر از کالاهای مشابه کالاهای انتخاب‌شده‌ی کاربر استفاده کنیم.v
	برای مثال برای رویکرد پیدا کردن کالاهای مشابه از فرمول زیر برای پیدا کردن امتیازها استفاده می‌کنیم، برای حالت 	کاربرهای مشابه نیز به همین شکل است. نکته‌ای که معمولا هست این هستش که رویکرد کالا-کالا به این دلیل که کالاها از 	پیچیدگی کمتری نسبت به کاربرها دارند معمولا بهتر جواب می‌دهند.


شباهت‌ در تابع‌ها:
کلا تو هر الگوریتمی که باید فاصله رو حساب کنیم(مثل KNN) یک ورودی شباهت داریم که معلوم می‌کنه چجور شباهت دو بردار رو در نظر بگیریم تا فاصله رو حساب کنیم. هر تابعی که با surprise scikit پیاده‌سازی شده‌است -که می‌شه همه‌ی تابع‌های بخش پیش‌بینی در بخش داده‌های تعاملی- یک ورودی sim_option می‌گیرد که کاربر می‌تونه اون‌ها رو تنظیم کنه. اولین چیزی که کاربر می‌تونه انتخاب کنه نوع شباهت است.
نوع شباهت
۴ نوع شباهت رو میشه در تابع انتخاب کرد که اینجا دونه دونه رو بگیم.(پیش‌فرض خود تابع اگر کاربر انتخابی نکند MSD است.)
    • cosine: این همون شباهت متداولی هست که بیایم cosinus  زاویه‌ی بین دو بردار رو به عنوان شباهت در نظر بگیریم. که این فرمول هم محاسبه‌ی همون cosinus زاویه‌ی بین دو بردار هست.








    • Msd: این تابع اندازه‌ی فاصله‌ی برداری دو تابع رو به عنوان فاصله در نظر می‌گیره؛ که یعنی معکوس این محاسبه رو به عنوان شباهت در نظر می‌گیره.(یک سری بحث‌ها هست(که من هم درست بلد نیستم راستش، درس آمار در ابعاد بالا(high-dimensional statistics) به امثال این موضوع می‌پردازه که اگر علاقه داشتید می‌تونید این درسvi رو بخونید به ما هم یاد بدید.) که تو ابعاد بالا cosine بهتر از این msd هستش، یکی از دلایل بدیهی‌ش همین‌ه که اون بین [1,-1] اسکیل می‌شه همیشه.)










    • pearson: کلا کاری که پیرسون می‌کنه این هستش که کوریلیشن خطی دو تا  X, Y random variable رو به دست می‌آره(اگه می‌خواید بیشتر بخونیدvii. پس فرمول کلی پیرسون به این شکل در میاد:



	که اگر بخوایم برای بردار بنویسیمش می‌شه:
 	




    • pearson_baseline: به جای means از baseline استفاده می‌کنه که میشه با تنظیم shrinkage جلوی over fit رو روی داده‌های کم گرفت.







نهایتا مقدار k و min_k نیز می‌تونه توسط کاربر وارد بشه که تعریف آن‌ها معلوم است. این تابع با استفاده از تابع knnGetInput صدا زده می‌شه. توجه کنید که کاربر اگر می‌خواهد مشخصات تابع رو عوض کند باید بلد باشه که هر کدوم آیا به نوع داده‌ای که ورودی می‌ده می‌خوره یا نه و از این دست مسائل. در حالت پیش‌فرض این تابع به ما نتیجه زیر رو برای داده‌های محدود می‌ده.

                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     
RMSE (testset)    1.0758  1.0724  1.0723  1.0719  1.0739  1.0733  0.0014  
MAE (testset)     0.8983  0.8957  0.8962  0.8949  0.8966  0.8963  0.0011  
Fit time          0.71    1.65    1.74    1.99    1.64    1.54    0.44 

تابع‌های Matrix Factorization_based 
این الگوریتم‌ها کار اصلی‌ای که می‌کنند این هست که روی ماتریس کالا-کاربر تجزیه انجام می‌دن(مشابه‌ش رو توی کاهش بعد با SVD که نویزها رو می‌گرفتیم دیدیم.viii) و ماتریس رو به ۲تا ماتریس مثلثی تجزیه می‌کنند. 


تعداد nfactor که تعداد ستون در ماتریس اول(ماتریس اول مربوط کاربرها است) و تعداد سطرها در ماتریس دوم(ماتریس دوم مربوط به کالاها است.) است یک طورهایی درجه‌ی آزادی دو ماتریس که قراره فیت بشوند رو نشون می‌ده ؛ که خب منطقا اگر خیلی زیاد باشند شاید over fit اتفاق بیفته که برای این یک سری جاها مثل بقیه‌ی جاها regularization روی اندازه‌ی دو ماتریس H, W انجام می‌دهند و مساله زیر رو(مثلا با SGD) حل می‌کنند.


۲ مدل مرسوم این تابع پیاده می‌شه که پایین جفتش رو بگیم.
تابع SVDMatrixFact
این الگوریتم در حالت کلی با بهینه کردن پارامترهای این تابع کار می‌کند. این تابع یکی از الگوریتم‌های معروف در مسابقه‌ی نت‌فلیکس مذکور بود که خوب هم جواب داد و بعد از اون معروف شد.ix



پس نتیجتا طبق توضیحات بالا باید چند دسته ورودی تابع بگیرد. دسته‌ی اول ورودی‌ها مربوط مقدار رندم اولیه‌ی بردارهای factor هستند که کاربر می‌تواند mean و std تابع نرمالی که رندم تولید می‌کند را عوض کند. دسته‌ی دوم تنظیمات مربوط به استفاده از SGD مثل n_epochs (تعداد انجام حلقه‌ی SGD که معمولا اردر انجام پیش‌فرض آن ۲۰ است.) و learning rateها. دسته‌ی سوم نیز انتخاب کاربر برای استفاده یا عدم استفاده از بایاس(۳جمله‌ی اول تابع امتیاز بالا) است.

تابع SVDPP
این تابع واقعیت الان به کار ما نمیاد. کلا این الگوریتم برای این به وجود اومد که یک سری امتیازدهی‌های implicit سوای امتیازدهی اصلی که بین کالا و کاربر اتفاق بیفته(مثلا مثل بوکمارک کردن، رد کردن کالا و…) وارد سیستم توصیه‌گر بشه. که خب پس این الگوریتم خیلی نمی‌تونه به عنوان «موتور» در بیاد و با توجه به کاربری هر سیستم توصیه‌گری باید تغییر کنه. الگوریتم از بهینه کردن تابع زیر به دست میاد، که اگه نگاه کنیم اگر اون بردار y که نشون‌دهنده‌ی ترجیحات implicit کاربر هست رو صفر در نظر بگیریم(مقدار پیش‌فرضش) همون تابع و الگوریتم قبلی نتیجه میشه.




ورودی‌هایی که باید به تابع داده بشوند هم که مثل بخش قبل هست.
تابع SVDMatrixFact روی داده‌ی محدود(۳۰۰تا فیلم اول) به شکل زیر عمل کرد.
Evaluating RMSE, MAE of algorithm SVD on 5 split(s).
                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     
RMSE (testset)    0.9897  0.9947  0.9899  0.9912  0.9922  0.9915  0.0018  
MAE (testset)     0.7815  0.7874  0.7824  0.7846  0.7824  0.7836  0.0021  
Fit time          44.90   42.62   41.20   41.14   40.14   42.00   1.65  
الگوریتم slopeOne
Slope one یک الگوریتم ساده است برای استفاده روی حالت فیلتر تعاملی که بعضا از الگوریتم‌های پیچیده هم بهتر جواب می‌ده؛ بعضی مواقع هم البته با الگوریتم‌ها و کارهای دیگه به صورت ترکیبی استفاده می‌شه.x که الگوریتمش هم به شکل زیر عمل می‌کنه:



که یعنی ما می‌خوایم امتیاز کاربر u به کالای i رو حساب کنیم، برای این کار میانگین امتیاز کاربر u رو با اختلاف نرمال‌شده‌ی امتیاز کالای i با کالاهای مرتبط با کالایi و u جمع می‌کنیم(کالای مرتبط با کالای i رو میشه به این شکل تعریف کرد که کالاهایی که توسط کاربر u استفاده شده‌اند و حداقل یک کاربر انتخاب‌کننده‌ی مشترک با i دارند.). یک طورهایی انگار رگرسیون بین کالاهای
مشترک رو بدون محاسبه‌ی شیب خط در نظر می‌گیریم.



همین دیگه.

الگوریتم Co-clustering
ریاضی این الگوریتم رو من نفهمیدم واقعیت. کلیت کاری که می‌کنه مثل این که این هستش که یک ماتریس M*N در نظر بگیریم(ماتریس تعامل کاربر-کالا اینجا)، بیایم یک سری زیرمجموعه از سطرها(یا ستون‌ها) در بیاریم که در ستون‌ها(یا سطرها) شبیه هم باشند. مشکل خوشه‌بندی خالی این هستش که چون اینجا ماتریس خیلی خالی هست و تعداد کالاهای مشترک بین دو کاربر کم هست خیلی منطقی نیست خوشه‌بندی رو برای مثال روی کاربرها انجام بدیم، چون فرض بگیرید ممکن هست که ۲ تا کاربر هر دوتا به موضوع x علاقه‌مند باشند ولی اشتراک انتخاب کالاشون خیلی کم باشه.
بعد از انجام co-clustering جوری که امتیاز یک کالا برای یک کاربر رو به دست می‌آریم به شکل زیر هست.

